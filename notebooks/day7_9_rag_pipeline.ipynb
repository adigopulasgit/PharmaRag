{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 5000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import faiss, pickle\n",
    "\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "\n",
    "# Reload FAISS index\n",
    "index = faiss.read_index(str(processed_dir / \"evidence_faiss.index\"))\n",
    "\n",
    "# Reload metadata\n",
    "with open(processed_dir / \"id_to_row.pkl\", \"rb\") as f:\n",
    "    id_to_row = pickle.load(f)\n",
    "\n",
    "print(\"Index size:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    q_emb = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    scores, idxs = index.search(q_emb, k)\n",
    "    results = []\n",
    "    for score, i in zip(scores[0], idxs[0]):\n",
    "        row = id_to_row[i]\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"ligand\": row.get(\"ligand_name\"),\n",
    "            \"smiles\": row.get(\"smiles\"),\n",
    "            \"target\": row.get(\"target\"),\n",
    "            \"activity_type\": row.get(\"activity_type\"),\n",
    "            \"value\": row.get(\"value\"),\n",
    "            \"pValue\": row.get(\"pValue\")\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž EGFR inhibitors\n",
      "  â€¢ 91663444.0 | Target: MLGNKRLGLSGLTLALSLLVCLGALAEAYPSKPDNPGEDAPAEDMARYYSALRHYINLITRQRYGKRSSPETLISDLLMRESTENVPRTRLEDPAMW | BindingDB_Ki=4.6 (p=nan, score=0.362)\n",
      "  â€¢ 44186669.0 | Target: MPPSISAFQAAYIGIEVLIALVSVPGNVLVIWAVKVNQALRDATFCFIVSLAVADVAVGALVIPLAILINIGPQTYFHTCLMVACPVLILTQSSILALLAIAVDRYLRVKIPLRYKMVVTPRRAAVAIAGCWILSFVVGLTPMFGWNNLSAVERAWAANGSMGEPVIKCEFEKVISMEYMVYFNFFVWVLPPLLLMVLIYLEVFYLIRKQLNKKVSASSGDPQKYYGKELKIAKSLALILFLFALSWLPLHILNCITLFCPSCHKPSILTYIAIFLTHGNSAMNPIVYAFRIQKFRVTFLKIWNDHFRCQPAPPIDEDLPEERPDD | BindingDB_Ki=2610.0 (p=nan, score=0.348)\n",
      "  â€¢ 137796736.0 | Target: MGFQKFSPFLALSILVLLQAGSLHAAPFRSALESSPADPATLSEDEARLLLAALVQNYVQMKASELEQEQEREGSRIIAQKRACDTATCVTHRLAGLLSRSGGVVKNNFVPTNVGSKAFGRRRRDLQA | BindingDB_Ki=0.05 (p=nan, score=0.344)\n",
      "\n",
      "ðŸ”Ž HER2 compounds with IC50 under 10 nM\n",
      "  â€¢ None | Target: None | IC50= 1851 (p=5.732593581247096, score=0.427)\n",
      "  â€¢ prop-2-en-1-yl heptanoate | Target: solubility | solubility_aqsoldb=-3.5976237668 (p=nan, score=0.425)\n",
      "  â€¢ None | Target: None | IC50= 1940 (p=5.7121982700697735, score=0.422)\n",
      "\n",
      "ðŸ”Ž CYP2D6 metabolism\n",
      "  â€¢ 5459446.0 | Target: CYP2D6 | cyp2d6_veith=0.0 (p=nan, score=0.634)\n",
      "  â€¢ 228569.0 | Target: CYP2D6 | cyp2d6_veith=0.0 (p=nan, score=0.633)\n",
      "  â€¢ 1276120.0 | Target: CYP2D6 | cyp2d6_veith=0.0 (p=nan, score=0.628)\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"EGFR inhibitors\",\n",
    "    \"HER2 compounds with IC50 under 10 nM\",\n",
    "    \"CYP2D6 metabolism\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nðŸ”Ž {q}\")\n",
    "    for r in retrieve(q, k=3):\n",
    "        print(f\"  â€¢ {r['ligand']} | Target: {r['target']} | \"\n",
    "              f\"{r['activity_type']}={r['value']} (p={r['pValue']}, score={r['score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d771548fda38499297df38b7a789e9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a3af158e9a4c9abe774a8f678c2a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1625df0a28aa4149b17b6871af0ef04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b26969f01246f68a4e442dd8150f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2d1c4e581947658abffa22830981d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c83a65ced02406ca9d3efbed64d3b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Summarize evidence for EGFR inhibitors.\n",
      "Evidence:\n",
      "91663444.0 (BindingDB_Ki=4.6, p=nan) on MLGNKRLGLSGLTLALSLLVCLGALAEAYPSKPDNPGEDAPAEDMARYYSALRHYINLITRQRYGKRSSPETLISDLLMRESTENVPRTRLEDPAMW\n",
      "TOX1633 (SR-p53=0.0, p=nan) on SR-p53\n",
      "TOX5312 (NR-AhR=0.0, p=nan) on NR-AhR\n",
      "TOX1636 (SR-p53=0.0, p=nan) on SR-p53\n",
      "TOX1431 (SR-p53=0.0, p=nan) on SR-p53\n",
      "\n",
      "Answer with citations.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "rag_llm = pipeline(\"text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "query = \"Summarize evidence for EGFR inhibitors.\"\n",
    "evidence = retrieve(query, k=5)\n",
    "\n",
    "context = \"\\n\".join([\n",
    "    f\"{e['ligand']} ({e['activity_type']}={e['value']}, p={e['pValue']}) on {e['target']}\"\n",
    "    for e in evidence\n",
    "])\n",
    "\n",
    "prompt = f\"Question: {query}\\nEvidence:\\n{context}\\n\\nAnswer with citations.\"\n",
    "print(rag_llm(prompt, max_length=200)[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use text2text-generation for FLAN-T5\n",
    "rag_llm = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    device_map=\"auto\"   # uses MPS on Mac if available\n",
    ")\n",
    "\n",
    "def cite_block(evidence):\n",
    "    lines = []\n",
    "    for e in evidence:\n",
    "        ligand = e.get(\"ligand\") or e.get(\"smiles\")\n",
    "        lines.append(\n",
    "            f\"{ligand} | Target={e['target']} | {e['activity_type']}={e['value']} | p={e['pValue']}\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "query = \"Summarize evidence for EGFR inhibitors.\"\n",
    "evidence = retrieve(query, k=5)   # <- your FAISS retriever\n",
    "context = cite_block(evidence)\n",
    "\n",
    "prompt = (\n",
    "    \"You are a scientific assistant. Summarize the evidence below in 3â€“5 bullets. \"\n",
    "    \"Each bullet MUST include a citation with ligand/target/value in parentheses.\\n\\n\"\n",
    "    f\"Evidence:\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "out = rag_llm(prompt, max_new_tokens=256, truncation=True)[0][\"generated_text\"]\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval_ms: 4216.097666998394 gen_ms: 14899.229374990682\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.perf_counter()\n",
    "evidence = retrieve(query, k=5)\n",
    "t1 = time.perf_counter()\n",
    "out = rag_llm(prompt, max_new_tokens=256, truncation=True)[0][\"generated_text\"]\n",
    "t2 = time.perf_counter()\n",
    "print(\"retrieval_ms:\", (t1-t0)*1000, \"gen_ms:\", (t2-t1)*1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
